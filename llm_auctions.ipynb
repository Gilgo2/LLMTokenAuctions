{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from strategies import *\n",
    "from bidder import Bidder\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.append(r'c:\\users\\ggoren\\PycharmProjects\\AGTProject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "auction_model_id = 'meta-llama/Llama-3.2-1B-instruct'\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    auction_model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(auction_model_id)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apply_chat_template(messages, tokens):\n",
    "    return f'<|im_start|>system\\n{messages[0][\"content\"]}.<|im_end|>\\n<|im_start|>user\\n{messages[1][\"content\"]}<|im_end|>\\n<|im_start|>assistant\\n{\"\".join(tokens)}'\n",
    "\n",
    "def get_next_word_probs(messages, tokens):\n",
    "    text = apply_chat_template(messages, tokens)\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\")\n",
    "\n",
    "    outputs = model(model_inputs.input_ids)\n",
    "    logits = outputs.logits\n",
    "\n",
    "    next_token_logits = logits[:, -1, :]  # Get the logits for the last token\n",
    "    next_token_probs = torch.nn.functional.softmax(next_token_logits, dim=-1)\n",
    "\n",
    "    # Get the top 100 most probable tokens\n",
    "    top_k = 100\n",
    "    top_probs, top_indices = torch.topk(next_token_probs, top_k, dim=-1)\n",
    "    return top_probs, top_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " import numpy as np\n",
    " def q_integral(p, b,t,i,value):\n",
    "    P = (p.T @ b)[t] - p[i][t] * b[i]\n",
    "    S = b.sum() - b[i]\n",
    "    return p[i][t] * value + (P - p[i][t] * S) * torch.log(torch.abs(value + S))\n",
    "\n",
    "def token_payment(p, b, t, i, q):\n",
    "    return 1/2 * ((q[t] - p[i][t]) * b[i] - (q_integral(p, b, t, i, b[i]) - q_integral(p, b,t, i, 0) - p[i][t] *b[i]))\n",
    "\n",
    "def update_payments(payments, p, b, q):\n",
    "    \"\"\"\n",
    "    Iterate every bidder and token to get its payments from the integral\n",
    "    :param payments: Current payment vector to update\n",
    "    :param p: Current bidder's distributions over token\n",
    "    :param b: Bidders' bid\n",
    "    :param q: Distribution aggregation\n",
    "    :return: Updated payments vector\n",
    "    \"\"\"\n",
    "    for i in range(b.shape[0]):\n",
    "        for t in range(p.shape[0]):\n",
    "            payment = token_payment(p, b, t, i, q).item()\n",
    "            payments[i] += max(payment, 0)\n",
    "    return payments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def qkl(b, combined_probs):\n",
    "    # Ensure both tensors are float type\n",
    "    b = b.float()  # Convert b to float if it's not already\n",
    "    combined_probs = combined_probs.float()  # Convert combined_probs to float\n",
    "\n",
    "    # Perform the matrix operation\n",
    "    result = combined_probs.T @ b / b.sum()\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_missing_tokens(tensor_a, tensor_b):\n",
    "    indices_a_not_in_b_mask = ~torch.isin(tensor_a, tensor_b)\n",
    "    indices_a_not_in_b = tensor_a[indices_a_not_in_b_mask].reshape(1, -1)\n",
    "    return indices_a_not_in_b\n",
    "\n",
    "def add_zero_probs_for_new_tokens(indices, probs, new_tokens):\n",
    "\n",
    "    indices = torch.cat([indices, new_tokens], dim=1)\n",
    "    zero_probs = torch.zeros_like(new_tokens)\n",
    "    probs = torch.cat([probs, zero_probs], dim=1)\n",
    "    return indices, probs\n",
    "\n",
    "def sort_tokens(indices, probs):\n",
    "    sorted_indices, sorted_order = torch.sort(indices)\n",
    "    sorted_probs = probs[0, sorted_order]\n",
    "    return sorted_indices, sorted_probs\n",
    "\n",
    "def sort_and_combine_dists(top_probs_alpha, top_indices_alpha, top_probs_beta, top_indices_beta):\n",
    "    beta_missing_tokens = get_missing_tokens(top_indices_alpha, top_indices_beta)\n",
    "    alpha_missing_tokens = get_missing_tokens(top_indices_beta, top_indices_alpha)\n",
    "\n",
    "    full_alpha_indices, full_alpha_probs = add_zero_probs_for_new_tokens(top_indices_alpha, top_probs_alpha, alpha_missing_tokens)\n",
    "    full_beta_indices, full_beta_probs = add_zero_probs_for_new_tokens(top_indices_beta, top_probs_beta, beta_missing_tokens)\n",
    "\n",
    "    sorted_alpha_indices, sorted_alpha_probs = sort_tokens(full_alpha_indices, full_alpha_probs)\n",
    "    sorted_beta_indices, sorted_beta_probs = sort_tokens(full_beta_indices, full_beta_probs)\n",
    "\n",
    "    combined_indices = torch.cat([sorted_alpha_indices, sorted_beta_indices])\n",
    "    combined_probs = torch.cat([sorted_alpha_probs, sorted_beta_probs])\n",
    "    return combined_indices, combined_probs\n",
    "\n",
    "\n",
    "def get_next_token(b, top_probs_alpha, top_indices_alpha, top_probs_beta, top_indices_beta, payments, temperature=0.06):\n",
    "    \"\"\"\n",
    "    This function receives distributions from both bidders, aggregates them into one distribution (q), calculates the costs\n",
    "    and samples the next token\n",
    "    :param b: Bidders' bid\n",
    "    :param top_probs_alpha: Distribution of Bidder alpha over tokens\n",
    "    :param top_indices_alpha: Mapping of indices to actual tokens for bidder alpha\n",
    "    :param top_probs_beta: Distribution of Bidder beta over tokens\n",
    "    :param top_indices_beta: Mapping of indices to actual tokens for bidder beta\n",
    "    :param payments: Vector of payments\n",
    "    :param temperature: Temperature parameter to control token sampling\n",
    "    :return: The next sampled token and induced payments.\n",
    "    \"\"\"\n",
    "    # combined_probs is p: A tensor for each bidder with dist over tokens\n",
    "    # combined_indices is the actual token\n",
    "    combined_indices, combined_probs = sort_and_combine_dists(top_probs_alpha, top_indices_alpha, top_probs_beta, top_indices_beta)\n",
    "    token_logits = qkl(combined_probs, b)\n",
    "    payments = update_payments(payments, combined_probs, b, token_logits)\n",
    "    token_temperature_logits = token_logits / temperature\n",
    "    token_dist = torch.softmax(token_temperature_logits, dim=0)\n",
    "    token = tokenizer.decode(combined_indices[0,torch.multinomial(token_dist, 1)].item())\n",
    "    return token, payments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_probs_from_distributions(chosen_token, top_probs_alpha, top_indices_alpha, top_probs_beta, top_indices_beta):\n",
    "    \"\"\"\n",
    "    This function extracts the probability of a chosen token from the given distributions of both bidders.\n",
    "    If the token is found in either distribution, return the probability; otherwise, return 0.\n",
    "    \n",
    "    :param chosen_token: The token for which we want to extract the probability.\n",
    "    :param top_probs_alpha: Distribution of Bidder alpha over tokens.\n",
    "    :param top_indices_alpha: Mapping of indices to actual tokens for Bidder alpha.\n",
    "    :param top_probs_beta: Distribution of Bidder beta over tokens.\n",
    "    :param top_indices_beta: Mapping of indices to actual tokens for Bidder beta.\n",
    "    :return: The probability of the chosen token from both bidders.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Token probability starts at 0\n",
    "    token_prob_alpha = 0.0\n",
    "    token_prob_beta = 0.0\n",
    "\n",
    "    # Convert the chosen token to its token ID using the tokenizer\n",
    "    chosen_token_id = tokenizer.encode(chosen_token, add_special_tokens=False)[0]\n",
    "\n",
    "    # Check if the token exists in top_indices_alpha\n",
    "    if chosen_token_id in top_indices_alpha:\n",
    "        # Get the index of the chosen token in top_indices_alpha\n",
    "        index_alpha = (top_indices_alpha == chosen_token_id).nonzero(as_tuple=True)[1]\n",
    "        # Add the corresponding probability from top_probs_alpha\n",
    "        token_prob_alpha += top_probs_alpha[0, index_alpha].item()\n",
    "\n",
    "    # Check if the token exists in top_indices_beta\n",
    "    if chosen_token_id in top_indices_beta:\n",
    "        # Get the index of the chosen token in top_indices_beta\n",
    "        index_beta = (top_indices_beta == chosen_token_id).nonzero(as_tuple=True)[1]\n",
    "        # Add the corresponding probability from top_probs_beta\n",
    "        token_prob_beta += top_probs_beta[0, index_beta].item()\n",
    "\n",
    "    return token_prob_alpha, token_prob_beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "messages_alpha = [\n",
    "    {\"role\": \"user\", \"content\": \"You are an expert of writing texts that naturally combines two ads together. Your choice of words and sentences is full of artistic flair. Do not include an intro, only write an ad.\"}, {\"role\":\"user\", \"content\":\"Write a two-sentence ad for a flight to Hawaii using Alpha Airlines. Ensure Alpha Airlines is at the beginning of each sentence.\"}\n",
    "]\n",
    "messages_beta = [\n",
    "    {\"role\": \"user\", \"content\": \"You are an expert of writing texts that naturally combines two ads together. Your choice of words and sentences is full of artistic flair, Do not include an intro, only write an ad.\"}, {\"role\":\"user\", \"content\":\"Write a two-sentence ad for a vacation in Hawaii at the Beta Resort. Ensure Beta Resort is at the beginning of each sentence.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def generate_text(alpha_airlines_bidder: Bidder, beta_resort_bidder: Bidder, sentence_limit=2, token_count=100, verbose = True):\n",
    "    start_time = time.time()\n",
    "    sentence_counter = 0\n",
    "    tokens = []\n",
    "    alpha_airlines_bid = alpha_airlines_bidder.get_bid(\"\".join(tokens))\n",
    "    beta_resort_bid = beta_resort_bidder.get_bid(\"\".join(tokens))\n",
    "    b = torch.tensor([alpha_airlines_bid, beta_resort_bid])\n",
    "    payments = np.zeros_like(b)\n",
    "    chosen_tokens_probs_result_alpha = []\n",
    "    chosen_tokens_probs_result_beta = []\n",
    "    chosen_tokens_payment_prob_ratio_result_alpha = []\n",
    "    chosen_tokens_payment_prob_ratio_result_beta = []\n",
    "    for _ in range(token_count):\n",
    "        top_probs_alpha, top_indices_alpha  = get_next_word_probs(messages_alpha, tokens)\n",
    "        top_probs_beta, top_indices_beta = get_next_word_probs(messages_beta, tokens)\n",
    "        next_token, payments = get_next_token(b, top_probs_alpha, top_indices_alpha, top_probs_beta, top_indices_beta, payments)\n",
    "\n",
    "        if verbose:\n",
    "            print(next_token, end='')\n",
    "\n",
    "        if next_token == \"<|im_end|>\" or \"<|\" in next_token or \"|>\" in next_token:\n",
    "                break\n",
    "\n",
    "        tokens.append(next_token)\n",
    "        chosen_token_probs_alpha, chosen_token_probs_beta= get_token_probs_from_distributions(next_token,top_probs_alpha=top_probs_alpha,top_indices_alpha=top_indices_alpha, top_probs_beta= top_probs_beta, top_indices_beta=top_indices_beta)\n",
    "        chosen_tokens_probs_result_alpha.append(chosen_token_probs_alpha)\n",
    "        chosen_tokens_probs_result_beta.append(chosen_token_probs_beta)\n",
    "        chosen_tokens_payment_prob_ratio_result_alpha.append(chosen_token_probs_alpha/ float(payments[0]))\n",
    "        chosen_tokens_payment_prob_ratio_result_beta.append(chosen_token_probs_beta/ float(payments[1]))\n",
    "\n",
    "        # Break after 2 sentences\n",
    "        if \".\" in next_token or \"!\" in next_token or \"?\" in next_token:\n",
    "            sentence_counter += 1\n",
    "            if sentence_counter >= sentence_limit:\n",
    "                break\n",
    "        alpha_airlines_bid = alpha_airlines_bidder.get_bid(\"\".join(tokens)) if payments[0] <= alpha_airlines_bidder.budget else 0.01\n",
    "        beta_resort_bid = beta_resort_bidder.get_bid(\"\".join(tokens)) if payments[1] <= beta_resort_bidder.budget else 0.01\n",
    "        b = torch.tensor([alpha_airlines_bid, beta_resort_bid])\n",
    "    if verbose:\n",
    "        print(\"\\n\", (time.time() - start_time) / 60, \"minutes\")\n",
    "\n",
    "    return \"\".join(tokens), payments ,chosen_tokens_probs_result_alpha, chosen_tokens_probs_result_beta, chosen_tokens_payment_prob_ratio_result_alpha, chosen_tokens_payment_prob_ratio_result_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "company_names = ['Alpha Airlines', 'Beta Resort']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_in_string(substring, main_string):\n",
    "    lower_main = main_string.lower()\n",
    "    lower_sub = substring.lower()\n",
    "    index = lower_main.find(lower_sub)\n",
    "    main_length = len(main_string)\n",
    "    \n",
    "    if index != -1:\n",
    "        return (main_length - index) / main_length  # Higher score for lower index, normalized by length\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Load a new instruction-following model, like flan-T5\n",
    "model_name = \"google/flan-t5-small\"  # Try flan-t5 models\n",
    "model_eval = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer_eval = AutoTokenizer.from_pretrained(model_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import torch\n",
    "import re\n",
    "\n",
    "def evaluate_outcome_using_llm(company_name, outcome, useOpenAI = True, openai_model_name='gpt-4o-mini', verbose=True):\n",
    "    if useOpenAI:\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "        if not api_key:\n",
    "            raise ValueError(\"OpenAI API key is not set. Please set the OPENAI_API_KEY environment variable.\")\n",
    "\n",
    "        openai.api_key = api_key\n",
    "\n",
    "        eval_prompt = f\"\"\"\n",
    "        You are an expert ad evaluator. Evaluate the quality of the following ad text for the company \"{company_name}\" based on relevance, coherence, and clarity.\n",
    "        It's very important that the companty's name \"{company_name}\" will be a part of the ad.\n",
    "\n",
    "        Ad Text:\n",
    "        {outcome}\n",
    "\n",
    "        Provide a single score between 1 and 10 that reflects the overall quality of the ad. Respond with **only the number** and nothing else.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=openai_model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a text evaluation assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": eval_prompt}\n",
    "            ],\n",
    "            max_tokens=2,  \n",
    "            temperature=0  \n",
    "        )\n",
    "\n",
    "        response_text = response['choices'][0]['message']['content'].strip()\n",
    "    else:\n",
    "        eval_prompt = f\"\"\"\n",
    "        Evaluate the following ad text for the company: \"{company_name}\".\n",
    "\n",
    "        Ad Text:\n",
    "        {outcome}\n",
    "\n",
    "        Provide **only** a number between 1 and 10. Do not provide any explanation or additional text. Just the number.\n",
    "        \"\"\"\n",
    "\n",
    "        # Tokenize the evaluation prompt\n",
    "        inputs = tokenizer_eval(eval_prompt, return_tensors=\"pt\").to(model_eval.device)\n",
    "\n",
    "        # Generate a response with a stricter token limit to prevent extra output\n",
    "        with torch.no_grad():\n",
    "            outputs = model_eval.generate(inputs[\"input_ids\"], matuvx_new_tokens=1000)  # Further limiting tokens to just 2\n",
    "\n",
    "        # Decode the response\n",
    "        response_text = tokenizer_eval.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "    if verbose:\n",
    "        print(\"LLM Response:\\n\", response_text)\n",
    "\n",
    "    match = re.match(r\"^\\d+$\", response_text) \n",
    "\n",
    "    if match:\n",
    "        score = int(match.group(0))\n",
    "        if 1 <= score <= 10:\n",
    "            return score\n",
    "\n",
    "    print(\"No valid score found in the response.\")\n",
    "    return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\n",
      " 4\n",
      "Evaluation Score: 4\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "comany_name = \"Beta Resort\"\n",
    "outcome = \"At the heart of paradise, the Beta Resort awaits your arrival. Here, the Alpha Airlines flight takes\"\n",
    "score = evaluate_outcome_using_llm(comany_name, outcome)\n",
    "print(f\"Evaluation Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Helper function to calculate averages\n",
    "def calculate_averages(total_values, num_tries):\n",
    "    return {key: value / num_tries for key, value in total_values.items()}\n",
    "\n",
    "# Helper function to build individual result dictionary\n",
    "def build_result_dict(name_appeared, avg_prob, score, payment, outcome, outcome_length, llm_evaluation_score, num_of_tokens, avg_token_payment_prob_ratio):\n",
    "    return {\n",
    "        \"outcome\": outcome,\n",
    "        \"outcome_length\": outcome_length,\n",
    "        \"num_of_tokens\": num_of_tokens,\n",
    "        \"name_appeared\": name_appeared,\n",
    "        \"avg_chosen_token_probability\": avg_prob,\n",
    "        \"name_appearance_score\": score,\n",
    "        \"llm_evaluation_score\": llm_evaluation_score,\n",
    "        \"payment\": payment,\n",
    "        \"avg_payment_per_token\": payment / num_of_tokens,\n",
    "        \"avg_token_payment_prob_ratio\": avg_token_payment_prob_ratio\n",
    "    }\n",
    "\n",
    "# Helper function to accumulate totals for averages\n",
    "def accumulate_totals(totals, values):\n",
    "    for key, value in values.items():\n",
    "        totals[key] += value\n",
    "\n",
    "def run_exp(num_tries: int, alpha_airlines_bidder: Bidder, beta_resort_bidder: Bidder, fileprefix: str, verbose=True):\n",
    "    result_alpha = []\n",
    "    result_beta = []\n",
    "\n",
    "    # Initialize totals for averages\n",
    "    totals_alpha = {\"name_appeared\": 0, \"avg_prob\": 0, \"name_appear_score\": 0, \"payment\": 0, \"llm_score\": 0, \"avg_pay_token\": 0, \"avg_pay_prob_ratio\": 0}\n",
    "    totals_beta = {\"name_appeared\": 0, \"avg_prob\": 0, \"name_appear_score\": 0, \"payment\": 0, \"llm_score\": 0, \"avg_pay_token\": 0,  \"avg_pay_prob_ratio\": 0}\n",
    "    total_outcome_length = 0\n",
    "    total_num_of_tokens = 0\n",
    "    openai_model_name = 'gpt-4o-mini'\n",
    "\n",
    "    for i in range(num_tries):\n",
    "        outcome, ad_payments, chosen_tokens_probs_result_alpha, chosen_tokens_probs_result_beta, chosen_tokens_payment_prob_ratio_result_alpha, chosen_tokens_payment_prob_ratio_result_beta = generate_text(\n",
    "            alpha_airlines_bidder=alpha_airlines_bidder, beta_resort_bidder=beta_resort_bidder)\n",
    "        \n",
    "        name_appear_alpha_score = string_in_string(substring=\"Alpha Airlines\", main_string=outcome)\n",
    "        name_appear_beta_score = string_in_string(substring=\"Beta Resort\", main_string=outcome)\n",
    "        \n",
    "        is_name_appear_alpha = 0 if name_appear_alpha_score == 0 else 1\n",
    "        is_name_appear_beta = 0 if name_appear_beta_score == 0 else 1\n",
    "        \n",
    "        num_of_tokens = len(chosen_tokens_probs_result_alpha)\n",
    "        \n",
    "        avg_chosen_token_prob_alpha = sum(chosen_tokens_probs_result_alpha) / num_of_tokens\n",
    "        avg_chosen_token_prob_beta = sum(chosen_tokens_probs_result_beta) / num_of_tokens\n",
    "        \n",
    "        avg_token_payment_prob_ratio_alpha = sum(chosen_tokens_payment_prob_ratio_result_alpha) / num_of_tokens\n",
    "        avg_token_payment_prob_ratio_beta = sum(chosen_tokens_payment_prob_ratio_result_beta) / num_of_tokens\n",
    "\n",
    "\n",
    "        llm_evaluation_score_alpha = evaluate_outcome_using_llm(\"Alpha Airlines\", outcome, openai_model_name=openai_model_name, verbose=verbose)\n",
    "        llm_evaluation_score_beta = evaluate_outcome_using_llm(\"Beta Resort\", outcome, openai_model_name=openai_model_name, verbose=verbose)\n",
    "\n",
    "        payment_alpha =  float(ad_payments[0])\n",
    "        payment_beta =  float(ad_payments[1])\n",
    "        \n",
    "        outcome_length = len(outcome)\n",
    "        total_outcome_length += outcome_length\n",
    "        total_num_of_tokens += num_of_tokens\n",
    "\n",
    "        # Append individual results\n",
    "        result_alpha.append(build_result_dict(is_name_appear_alpha, avg_chosen_token_prob_alpha, name_appear_alpha_score, payment_alpha, outcome, outcome_length, llm_evaluation_score_alpha, num_of_tokens, avg_token_payment_prob_ratio_alpha))\n",
    "        result_beta.append(build_result_dict(is_name_appear_beta, avg_chosen_token_prob_beta, name_appear_beta_score, payment_beta, outcome, outcome_length, llm_evaluation_score_beta, num_of_tokens, avg_token_payment_prob_ratio_beta))\n",
    "        \n",
    "\n",
    "        # Accumulate totals for Alpha and Beta\n",
    "        accumulate_totals(totals_alpha, {\"name_appeared\": is_name_appear_alpha, \"avg_prob\": avg_chosen_token_prob_alpha, \"name_appear_score\": name_appear_alpha_score, \"payment\": payment_alpha, \"llm_score\": llm_evaluation_score_alpha, \"avg_pay_token\": payment_alpha/num_of_tokens, \"avg_pay_prob_ratio\": avg_token_payment_prob_ratio_alpha})\n",
    "        accumulate_totals(totals_beta, {\"name_appeared\": is_name_appear_beta, \"avg_prob\": avg_chosen_token_prob_beta, \"name_appear_score\": name_appear_beta_score, \"payment\": payment_beta, \"llm_score\": llm_evaluation_score_beta, \"avg_pay_token\": payment_beta/num_of_tokens, \"avg_pay_prob_ratio\": avg_token_payment_prob_ratio_beta})\n",
    "\n",
    "    # Calculate averages\n",
    "    avg_alpha = calculate_averages(totals_alpha, num_tries)\n",
    "    avg_beta = calculate_averages(totals_beta, num_tries)\n",
    "    avg_outcome_length = total_outcome_length / num_tries\n",
    "    avg_num_of_tokens = total_num_of_tokens / num_tries\n",
    "\n",
    "    # save input parameters\n",
    "    input_alpha = {\"bid\": alpha_airlines_bidder.bid, \"strategy\": alpha_airlines_bidder.strategy_func.__name__,\n",
    "                   \"budget\": alpha_airlines_bidder.budget, \"company_name\": alpha_airlines_bidder.bidder_company}\n",
    "    input_beta = {\"bid\": beta_resort_bidder.bid, \"strategy\": beta_resort_bidder.strategy_func.__name__,\n",
    "                   \"budget\": beta_resort_bidder.budget, \"company_name\": beta_resort_bidder.bidder_company}\n",
    "\n",
    "    # Structuring results in a JSON-compatible dictionary\n",
    "    results = {\n",
    "        \"Alpha Airlines\": {\n",
    "            \"input\": input_alpha,\n",
    "            \"individual_results\": result_alpha,\n",
    "            \"averages\": avg_alpha\n",
    "        },\n",
    "        \"Beta Resort\": {\n",
    "            \"input\": input_beta,\n",
    "            \"individual_results\": result_beta,\n",
    "            \"averages\": avg_beta\n",
    "        },\n",
    "        \"averages\": {\n",
    "            \"avg_outcome_length\": avg_outcome_length,\n",
    "            \"avg_num_of_tokens\": avg_num_of_tokens\n",
    "        },\n",
    "        'auction_model': auction_model_id,\n",
    "        'eval_model': openai_model_name\n",
    "    }\n",
    "\n",
    "    # Generating output file name\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")  # Current date and time\n",
    "    output_file = f\"{fileprefix}_experiment_results_{num_tries}_tries_{timestamp}.json\"\n",
    "\n",
    "    # Writing the results into a JSON file\n",
    "    with open(output_file, 'w') as file:\n",
    "        json.dump(results, file, indent=4)\n",
    "\n",
    "    return result_alpha, result_beta, output_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At the heart of paradise, the Beta Resort awaits your arrival. Here, the Alpha Airlines flight takes\n",
      " 5.386965954303742 minutes\n",
      "LLM Response:\n",
      " 6\n",
      "LLM Response:\n",
      " 4\n"
     ]
    }
   ],
   "source": [
    "alpha_airlines_bidder = Bidder(2.0, decreasing_based_on_position_strategy, 'Alpha Airlines', budget=12)\n",
    "beta_resort_bidder = Bidder(3.0, decreasing_based_on_position_strategy, 'Beta Resort', budget=12)\n",
    "num_tries = 1\n",
    "\n",
    "results_3_2_alpha, results_3_2_beta, filename = run_exp(\n",
    "    num_tries=num_tries, \n",
    "    alpha_airlines_bidder=alpha_airlines_bidder, \n",
    "    beta_resort_bidder=beta_resort_bidder,\n",
    "    fileprefix=\"decreasing_based_on_position_strategy\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At the heart of paradise, the Beta Resort awaits your arrival. Dive into the crystal-clear waters of Hawaii's azure seas, where Alpha Airlines helms your journey to the ultimate destination.\n",
      " 11.21407786210378 minutes\n",
      "LLM Response:\n",
      " 6\n",
      "LLM Response:\n",
      " 7\n",
      "At the heart of paradise, the Beta Resort awaits your arrival. Here, the Alpha Airlines flight to Hawaii takes you to the heart of paradise, where the Beta Resort awaits your arrival.\n",
      " 9.691122070948284 minutes\n",
      "LLM Response:\n",
      " 6\n",
      "LLM Response:\n",
      " 7\n"
     ]
    }
   ],
   "source": [
    "alpha_airlines_bidder = Bidder(2.0, naive_strategy, 'Alpha Airlines', budget=12)\n",
    "beta_resort_bidder = Bidder(3.0, naive_strategy, 'Beta Resort', budget=12)\n",
    "num_tries = 2\n",
    "\n",
    "results_3_2_alpha, results_3_2_beta, filename = run_exp(\n",
    "    num_tries=num_tries, \n",
    "    alpha_airlines_bidder=alpha_airlines_bidder, \n",
    "    beta_resort_bidder=beta_resort_bidder,\n",
    "    fileprefix=\"naive\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_3_2_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_3_2_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcome, ad_payments = generate_text(alpha_airlines_bidder=Bidder(2.0, name_contest_strategy, 'Alpha Airlines', budget=12),\n",
    "                                     beta_resort_bidder=Bidder(3.0, naive_strategy, 'Beta Resort', budget=12), verbose=True)\n",
    "print(ad_payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcome, ad_payments = generate_text(alpha_airlines_bidder=Bidder(2.0, name_first_strategy, 'Alpha Airlines', budget=12),\n",
    "                                     beta_resort_bidder=Bidder(3.0, naive_strategy, 'Beta Resort',budget=12), verbose=True)\n",
    "print(ad_payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcome, ad_payments = generate_text(alpha_airlines_bidder=Bidder(2.0, naive_strategy, 'Alpha Airlines', budget=12),\n",
    "                                     beta_resort_bidder=Bidder(3.0, naive_strategy, 'Beta Resort', budget=12), verbose=True)\n",
    "print(ad_payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcome, ad_payments = generate_text(alpha_airlines_bidder=Bidder(3.0, name_contest_strategy, 'Alpha Airlines', budget=12),\n",
    "                                     beta_resort_bidder=Bidder(3.0, naive_strategy, 'Beta Resort', budget=12), verbose=True)\n",
    "print(ad_payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcome, ad_payments = generate_text(alpha_airlines_bidder=Bidder(3.0, name_first_strategy, 'Alpha Airlines', budget=12),\n",
    "                                     beta_resort_bidder=Bidder(3.0, naive_strategy, 'Beta Resort', budget=12), verbose=True)\n",
    "print(ad_payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcome, ad_payments = generate_text(alpha_airlines_bidder=Bidder(3.0, naive_strategy, 'Alpha Airlines', budget=12),\n",
    "                                     beta_resort_bidder=Bidder(3.0, naive_strategy, 'Beta Resort',budget=12), verbose=True)\n",
    "print(ad_payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcome, ad_payments = generate_text(alpha_airlines_bidder=Bidder(4.0, name_contest_strategy, 'Alpha Airlines', budget=12),\n",
    "                                     beta_resort_bidder=Bidder(3.0, naive_strategy, 'Beta Resort', budget=12), verbose=True)\n",
    "print(ad_payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcome, ad_payments = generate_text(alpha_airlines_bidder=Bidder(4.0, name_first_strategy, 'Alpha Airlines', budget=12),\n",
    "                                     beta_resort_bidder=Bidder(3.0, naive_strategy, 'Beta Resort', budget=12), verbose=True)\n",
    "print(ad_payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcome, ad_payments = generate_text(alpha_airlines_bidder=Bidder(4.0, naive_strategy, 'Alpha Airlines', budget=12),\n",
    "                                     beta_resort_bidder=Bidder(3.0, naive_strategy, 'Beta Resort',budget=12), verbose=True)\n",
    "print(ad_payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
