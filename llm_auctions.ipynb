{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from strategies import *\n",
    "from bidder import Bidder\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.append(r'c:\\users\\ggoren\\PycharmProjects\\AGTProject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mayha\\OneDrive\\Desktop\\year 4\\algs and incentives\\LLMTokenAuctions\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "auction_model_id = \"Qwen/Qwen2-1.5B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    auction_model_id,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(auction_model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apply_chat_template(messages, tokens):\n",
    "    return f'<|im_start|>system\\n{messages[0][\"content\"]}.<|im_end|>\\n<|im_start|>user\\n{messages[1][\"content\"]}<|im_end|>\\n<|im_start|>assistant\\n{\"\".join(tokens)}'\n",
    "\n",
    "def get_next_word_probs(messages, tokens):\n",
    "    text = apply_chat_template(messages, tokens)\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\")\n",
    "\n",
    "    outputs = model(model_inputs.input_ids)\n",
    "    logits = outputs.logits\n",
    "\n",
    "    next_token_logits = logits[:, -1, :]  # Get the logits for the last token\n",
    "    next_token_probs = torch.nn.functional.softmax(next_token_logits, dim=-1)\n",
    "\n",
    "    # Get the top 100 most probable tokens\n",
    "    top_k = 100\n",
    "    top_probs, top_indices = torch.topk(next_token_probs, top_k, dim=-1)\n",
    "    return top_probs, top_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " import numpy as np\n",
    " def q_integral(p, b,t,i,value):\n",
    "    P = (p.T @ b)[t] - p[i][t] * b[i]\n",
    "    S = b.sum() - b[i]\n",
    "    return p[i][t] * value + (P - p[i][t] * S) * torch.log(torch.abs(value + S))\n",
    "\n",
    "def token_payment(p, b, t, i, q):\n",
    "    return 1/2 * ((q[t] - p[i][t]) * b[i] - (q_integral(p, b, t, i, b[i]) - q_integral(p, b,t, i, 0) - p[i][t] *b[i]))\n",
    "\n",
    "def update_payments(payments, p, b, q):\n",
    "    \"\"\"\n",
    "    Iterate every bidder and token to get its payments from the integral\n",
    "    :param payments: Current payment vector to update\n",
    "    :param p: Current bidder's distributions over token\n",
    "    :param b: Bidders' bid\n",
    "    :param q: Distribution aggregation\n",
    "    :return: Updated payments vector\n",
    "    \"\"\"\n",
    "    for i in range(b.shape[0]):\n",
    "        for t in range(p.shape[0]):\n",
    "            payment = token_payment(p, b, t, i, q).item()\n",
    "            payments[i] += max(payment, 0)\n",
    "    return payments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def qkl(b, combined_probs):\n",
    "    # Ensure both tensors are float type\n",
    "    b = b.float()  # Convert b to float if it's not already\n",
    "    combined_probs = combined_probs.float()  # Convert combined_probs to float\n",
    "\n",
    "    # Perform the matrix operation\n",
    "    result = combined_probs.T @ b / b.sum()\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_missing_tokens(tensor_a, tensor_b):\n",
    "    indices_a_not_in_b_mask = ~torch.isin(tensor_a, tensor_b)\n",
    "    indices_a_not_in_b = tensor_a[indices_a_not_in_b_mask].reshape(1, -1)\n",
    "    return indices_a_not_in_b\n",
    "\n",
    "def add_zero_probs_for_new_tokens(indices, probs, new_tokens):\n",
    "\n",
    "    indices = torch.cat([indices, new_tokens], dim=1)\n",
    "    zero_probs = torch.zeros_like(new_tokens)\n",
    "    probs = torch.cat([probs, zero_probs], dim=1)\n",
    "    return indices, probs\n",
    "\n",
    "def sort_tokens(indices, probs):\n",
    "    sorted_indices, sorted_order = torch.sort(indices)\n",
    "    sorted_probs = probs[0, sorted_order]\n",
    "    return sorted_indices, sorted_probs\n",
    "\n",
    "def sort_and_combine_dists(top_probs_alpha, top_indices_alpha, top_probs_beta, top_indices_beta):\n",
    "    beta_missing_tokens = get_missing_tokens(top_indices_alpha, top_indices_beta)\n",
    "    alpha_missing_tokens = get_missing_tokens(top_indices_beta, top_indices_alpha)\n",
    "\n",
    "    full_alpha_indices, full_alpha_probs = add_zero_probs_for_new_tokens(top_indices_alpha, top_probs_alpha, alpha_missing_tokens)\n",
    "    full_beta_indices, full_beta_probs = add_zero_probs_for_new_tokens(top_indices_beta, top_probs_beta, beta_missing_tokens)\n",
    "\n",
    "    sorted_alpha_indices, sorted_alpha_probs = sort_tokens(full_alpha_indices, full_alpha_probs)\n",
    "    sorted_beta_indices, sorted_beta_probs = sort_tokens(full_beta_indices, full_beta_probs)\n",
    "\n",
    "    combined_indices = torch.cat([sorted_alpha_indices, sorted_beta_indices])\n",
    "    combined_probs = torch.cat([sorted_alpha_probs, sorted_beta_probs])\n",
    "    return combined_indices, combined_probs\n",
    "\n",
    "\n",
    "def get_next_token(b, top_probs_alpha, top_indices_alpha, top_probs_beta, top_indices_beta, payments, temperature=0.06):\n",
    "    \"\"\"\n",
    "    This function receives distributions from both bidders, aggregates them into one distribution (q), calculates the costs\n",
    "    and samples the next token\n",
    "    :param b: Bidders' bid\n",
    "    :param top_probs_alpha: Distribution of Bidder alpha over tokens\n",
    "    :param top_indices_alpha: Mapping of indices to actual tokens for bidder alpha\n",
    "    :param top_probs_beta: Distribution of Bidder beta over tokens\n",
    "    :param top_indices_beta: Mapping of indices to actual tokens for bidder beta\n",
    "    :param payments: Vector of payments\n",
    "    :param temperature: Temperature parameter to control token sampling\n",
    "    :return: The next sampled token and induced payments.\n",
    "    \"\"\"\n",
    "    # combined_probs is p: A tensor for each bidder with dist over tokens\n",
    "    # combined_indices is the actual token\n",
    "    combined_indices, combined_probs = sort_and_combine_dists(top_probs_alpha, top_indices_alpha, top_probs_beta, top_indices_beta)\n",
    "    token_logits = qkl(combined_probs, b)\n",
    "    payments = update_payments(payments, combined_probs, b, token_logits)\n",
    "    token_temperature_logits = token_logits / temperature\n",
    "    token_dist = torch.softmax(token_temperature_logits, dim=0)\n",
    "    token = tokenizer.decode(combined_indices[0,torch.multinomial(token_dist, 1)].item())\n",
    "    return token, payments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_probs_from_distributions(chosen_token, top_probs_alpha, top_indices_alpha, top_probs_beta, top_indices_beta):\n",
    "    \"\"\"\n",
    "    This function extracts the probability of a chosen token from the given distributions of both bidders.\n",
    "    If the token is found in either distribution, return the probability; otherwise, return 0.\n",
    "    \n",
    "    :param chosen_token: The token for which we want to extract the probability.\n",
    "    :param top_probs_alpha: Distribution of Bidder alpha over tokens.\n",
    "    :param top_indices_alpha: Mapping of indices to actual tokens for Bidder alpha.\n",
    "    :param top_probs_beta: Distribution of Bidder beta over tokens.\n",
    "    :param top_indices_beta: Mapping of indices to actual tokens for Bidder beta.\n",
    "    :return: The probability of the chosen token from both bidders.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Token probability starts at 0\n",
    "    token_prob_alpha = 0.0\n",
    "    token_prob_beta = 0.0\n",
    "\n",
    "    # Convert the chosen token to its token ID using the tokenizer\n",
    "    chosen_token_id = tokenizer.encode(chosen_token, add_special_tokens=False)[0]\n",
    "\n",
    "    # Check if the token exists in top_indices_alpha\n",
    "    if chosen_token_id in top_indices_alpha:\n",
    "        # Get the index of the chosen token in top_indices_alpha\n",
    "        index_alpha = (top_indices_alpha == chosen_token_id).nonzero(as_tuple=True)[1]\n",
    "        # Add the corresponding probability from top_probs_alpha\n",
    "        token_prob_alpha += top_probs_alpha[0, index_alpha].item()\n",
    "\n",
    "    # Check if the token exists in top_indices_beta\n",
    "    if chosen_token_id in top_indices_beta:\n",
    "        # Get the index of the chosen token in top_indices_beta\n",
    "        index_beta = (top_indices_beta == chosen_token_id).nonzero(as_tuple=True)[1]\n",
    "        # Add the corresponding probability from top_probs_beta\n",
    "        token_prob_beta += top_probs_beta[0, index_beta].item()\n",
    "\n",
    "    return token_prob_alpha, token_prob_beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "messages_alpha = [\n",
    "    {\"role\": \"user\", \"content\": \"You are an expert of writing texts that naturally combines two ads together. Your choice of words and sentences is full of artistic flair. Do not include an intro, only write an ad.\"}, {\"role\":\"user\", \"content\":\"Write a two-sentence ad for a flight to Hawaii using Alpha Airlines. Ensure Alpha Airlines is at the beginning of each sentence.\"}\n",
    "]\n",
    "messages_beta = [\n",
    "    {\"role\": \"user\", \"content\": \"You are an expert of writing texts that naturally combines two ads together. Your choice of words and sentences is full of artistic flair, Do not include an intro, only write an ad.\"}, {\"role\":\"user\", \"content\":\"Write a two-sentence ad for a vacation in Hawaii at the Beta Resort. Ensure Beta Resort is at the beginning of each sentence.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_alpha_competing = [\n",
    "    {\"role\": \"user\", \"content\": \"You are an expert of writing texts that naturally combines two ads together. Your choice of words and sentences is full of artistic flair, Do not include an intro, only write an ad.\"}, {\"role\":\"user\", \"content\":\"Write a two-sentence ad for a vacation in Hawaii at the Alpha Resort. Ensure Alpha Resort is at the beginning of each sentence.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def generate_text(alpha_airlines_bidder: Bidder, beta_resort_bidder: Bidder, sentence_limit=2, token_count=100, verbose = True):\n",
    "    start_time = time.time()\n",
    "    sentence_counter = 0\n",
    "    tokens = []\n",
    "    alpha_airlines_bid = alpha_airlines_bidder.get_bid(\"\".join(tokens))\n",
    "    beta_resort_bid = beta_resort_bidder.get_bid(\"\".join(tokens))\n",
    "    b = torch.tensor([alpha_airlines_bid, beta_resort_bid])\n",
    "    payments = np.zeros_like(b)\n",
    "    chosen_tokens_probs_result_alpha = []\n",
    "    chosen_tokens_probs_result_beta = []\n",
    "    chosen_tokens_payment_prob_ratio_result_alpha = []\n",
    "    chosen_tokens_payment_prob_ratio_result_beta = []\n",
    "    for _ in range(token_count):\n",
    "        top_probs_alpha, top_indices_alpha  = get_next_word_probs(alpha_airlines_bidder.messages_alpha, tokens)\n",
    "        top_probs_beta, top_indices_beta = get_next_word_probs(beta_resort_bidder.messages_beta, tokens)\n",
    "        next_token, payments = get_next_token(b, top_probs_alpha, top_indices_alpha, top_probs_beta, top_indices_beta, payments)\n",
    "\n",
    "        if verbose:\n",
    "            print(next_token, end='')\n",
    "\n",
    "        if next_token == \"<|im_end|>\" or \"<|\" in next_token or \"|>\" in next_token:\n",
    "                break\n",
    "\n",
    "        tokens.append(next_token)\n",
    "        chosen_token_probs_alpha, chosen_token_probs_beta= get_token_probs_from_distributions(next_token,top_probs_alpha=top_probs_alpha,top_indices_alpha=top_indices_alpha, top_probs_beta= top_probs_beta, top_indices_beta=top_indices_beta)\n",
    "        chosen_tokens_probs_result_alpha.append(chosen_token_probs_alpha)\n",
    "        chosen_tokens_probs_result_beta.append(chosen_token_probs_beta)\n",
    "        chosen_tokens_payment_prob_ratio_result_alpha.append(chosen_token_probs_alpha/ float(payments[0]))\n",
    "        chosen_tokens_payment_prob_ratio_result_beta.append(chosen_token_probs_beta/ float(payments[1]))\n",
    "\n",
    "        # Break after 2 sentences\n",
    "        if \".\" in next_token or \"!\" in next_token or \"?\" in next_token:\n",
    "            sentence_counter += 1\n",
    "            if sentence_counter >= sentence_limit:\n",
    "                break\n",
    "        alpha_airlines_bid = alpha_airlines_bidder.get_bid(\"\".join(tokens)) if payments[0] <= alpha_airlines_bidder.budget else 0.01\n",
    "        beta_resort_bid = beta_resort_bidder.get_bid(\"\".join(tokens)) if payments[1] <= beta_resort_bidder.budget else 0.01\n",
    "        b = torch.tensor([alpha_airlines_bid, beta_resort_bid])\n",
    "    if verbose:\n",
    "        print(\"\\n\", (time.time() - start_time) / 60, \"minutes\")\n",
    "\n",
    "    return \"\".join(tokens), payments ,chosen_tokens_probs_result_alpha, chosen_tokens_probs_result_beta, chosen_tokens_payment_prob_ratio_result_alpha, chosen_tokens_payment_prob_ratio_result_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "company_names = ['Alpha Airlines', 'Beta Resort']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_in_string(substring, main_string):\n",
    "    lower_main = main_string.lower()\n",
    "    lower_sub = substring.lower()\n",
    "    index = lower_main.find(lower_sub)\n",
    "    main_length = len(main_string)\n",
    "    \n",
    "    if index != -1:\n",
    "        return (main_length - index) / main_length  # Higher score for lower index, normalized by length\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Load a new instruction-following model, like flan-T5\n",
    "model_name = \"google/flan-t5-small\"  # Try flan-t5 models\n",
    "model_eval = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer_eval = AutoTokenizer.from_pretrained(model_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import torch\n",
    "import re\n",
    "\n",
    "def evaluate_outcome_using_llm(company_name, outcome, useOpenAI = True, openai_model_name='gpt-4o-mini', verbose=True):\n",
    "    if useOpenAI:\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "        if not api_key:\n",
    "            raise ValueError(\"OpenAI API key is not set. Please set the OPENAI_API_KEY environment variable.\")\n",
    "\n",
    "        openai.api_key = api_key\n",
    "\n",
    "        eval_prompt = f\"\"\"\n",
    "        You are an expert ad evaluator. Evaluate the quality of the following ad text for the company \"{company_name}\" based on relevance, coherence, and clarity.\n",
    "        It's very important that the companty's name \"{company_name}\" will be a part of the ad.\n",
    "\n",
    "        Ad Text:\n",
    "        {outcome}\n",
    "\n",
    "        Provide a single score between 1 and 10 that reflects the overall quality of the ad. Respond with **only the number** and nothing else.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=openai_model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a text evaluation assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": eval_prompt}\n",
    "            ],\n",
    "            max_tokens=2,  \n",
    "            temperature=0  \n",
    "        )\n",
    "\n",
    "        response_text = response['choices'][0]['message']['content'].strip()\n",
    "    else:\n",
    "        eval_prompt = f\"\"\"\n",
    "        Evaluate the following ad text for the company: \"{company_name}\".\n",
    "\n",
    "        Ad Text:\n",
    "        {outcome}\n",
    "\n",
    "        Provide **only** a number between 1 and 10. Do not provide any explanation or additional text. Just the number.\n",
    "        \"\"\"\n",
    "\n",
    "        # Tokenize the evaluation prompt\n",
    "        inputs = tokenizer_eval(eval_prompt, return_tensors=\"pt\").to(model_eval.device)\n",
    "\n",
    "        # Generate a response with a stricter token limit to prevent extra output\n",
    "        with torch.no_grad():\n",
    "            outputs = model_eval.generate(inputs[\"input_ids\"], matuvx_new_tokens=1000)  # Further limiting tokens to just 2\n",
    "\n",
    "        # Decode the response\n",
    "        response_text = tokenizer_eval.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "    if verbose:\n",
    "        print(\"LLM Response:\\n\", response_text)\n",
    "\n",
    "    match = re.match(r\"^\\d+$\", response_text) \n",
    "\n",
    "    if match:\n",
    "        score = int(match.group(0))\n",
    "        if 1 <= score <= 10:\n",
    "            return score\n",
    "\n",
    "    print(\"No valid score found in the response.\")\n",
    "    return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\n",
      " 5\n",
      "Evaluation Score: 5\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "comany_name = \"Beta Resort\"\n",
    "outcome = \"At the heart of paradise, the Beta Resort awaits your arrival. Here, the Alpha Airlines flight takes\"\n",
    "score = evaluate_outcome_using_llm(comany_name, outcome)\n",
    "print(f\"Evaluation Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Helper function to calculate averages\n",
    "def calculate_averages(total_values, num_tries):\n",
    "    return {key: value / num_tries for key, value in total_values.items()}\n",
    "\n",
    "# Helper function to build individual result dictionary\n",
    "def build_result_dict(name_appeared, avg_prob, score, payment, outcome, outcome_length, llm_evaluation_score, num_of_tokens, avg_token_payment_prob_ratio):\n",
    "    return {\n",
    "        \"outcome\": outcome,\n",
    "        \"outcome_length\": outcome_length,\n",
    "        \"num_of_tokens\": num_of_tokens,\n",
    "        \"name_appeared\": name_appeared,\n",
    "        \"avg_chosen_token_probability\": avg_prob,\n",
    "        \"name_appearance_score\": score,\n",
    "        \"llm_evaluation_score\": llm_evaluation_score,\n",
    "        \"payment\": payment,\n",
    "        \"avg_payment_per_token\": payment / num_of_tokens,\n",
    "        \"avg_token_payment_prob_ratio\": avg_token_payment_prob_ratio\n",
    "    }\n",
    "\n",
    "# Helper function to accumulate totals for averages\n",
    "def accumulate_totals(totals, values):\n",
    "    for key, value in values.items():\n",
    "        totals[key] += value\n",
    "\n",
    "def run_exp(num_tries: int, alpha_airlines_bidder: Bidder, beta_resort_bidder: Bidder, fileprefix: str, verbose=True):\n",
    "    result_alpha = []\n",
    "    result_beta = []\n",
    "\n",
    "    # Initialize totals for averages\n",
    "    totals_alpha = {\"name_appeared\": 0, \"avg_prob\": 0, \"name_appear_score\": 0, \"payment\": 0, \"llm_score\": 0, \"avg_pay_token\": 0, \"avg_pay_prob_ratio\": 0}\n",
    "    totals_beta = {\"name_appeared\": 0, \"avg_prob\": 0, \"name_appear_score\": 0, \"payment\": 0, \"llm_score\": 0, \"avg_pay_token\": 0,  \"avg_pay_prob_ratio\": 0}\n",
    "    total_outcome_length = 0\n",
    "    total_num_of_tokens = 0\n",
    "    openai_model_name = 'gpt-4o-mini'\n",
    "\n",
    "    for i in range(num_tries):\n",
    "        outcome, ad_payments, chosen_tokens_probs_result_alpha, chosen_tokens_probs_result_beta, chosen_tokens_payment_prob_ratio_result_alpha, chosen_tokens_payment_prob_ratio_result_beta = generate_text(\n",
    "            alpha_airlines_bidder=alpha_airlines_bidder, beta_resort_bidder=beta_resort_bidder)\n",
    "        \n",
    "        name_appear_alpha_score = string_in_string(substring=alpha_airlines_bidder.bidder_company, main_string=outcome)\n",
    "        name_appear_beta_score = string_in_string(substring=beta_resort_bidder.bidder_company, main_string=outcome)\n",
    "        \n",
    "        is_name_appear_alpha = 0 if name_appear_alpha_score == 0 else 1\n",
    "        is_name_appear_beta = 0 if name_appear_beta_score == 0 else 1\n",
    "        \n",
    "        num_of_tokens = len(chosen_tokens_probs_result_alpha)\n",
    "        \n",
    "        avg_chosen_token_prob_alpha = sum(chosen_tokens_probs_result_alpha) / num_of_tokens\n",
    "        avg_chosen_token_prob_beta = sum(chosen_tokens_probs_result_beta) / num_of_tokens\n",
    "        \n",
    "        avg_token_payment_prob_ratio_alpha = sum(chosen_tokens_payment_prob_ratio_result_alpha) / num_of_tokens\n",
    "        avg_token_payment_prob_ratio_beta = sum(chosen_tokens_payment_prob_ratio_result_beta) / num_of_tokens\n",
    "\n",
    "\n",
    "        llm_evaluation_score_alpha = evaluate_outcome_using_llm(alpha_airlines_bidder.bidder_company, outcome, openai_model_name=openai_model_name, verbose=verbose)\n",
    "        llm_evaluation_score_beta = evaluate_outcome_using_llm(beta_resort_bidder.bidder_company, outcome, openai_model_name=openai_model_name, verbose=verbose)\n",
    "\n",
    "        payment_alpha =  float(ad_payments[0])\n",
    "        payment_beta =  float(ad_payments[1])\n",
    "        \n",
    "        outcome_length = len(outcome)\n",
    "        total_outcome_length += outcome_length\n",
    "        total_num_of_tokens += num_of_tokens\n",
    "\n",
    "        # Append individual results\n",
    "        result_alpha.append(build_result_dict(is_name_appear_alpha, avg_chosen_token_prob_alpha, name_appear_alpha_score, payment_alpha, outcome, outcome_length, llm_evaluation_score_alpha, num_of_tokens, avg_token_payment_prob_ratio_alpha))\n",
    "        result_beta.append(build_result_dict(is_name_appear_beta, avg_chosen_token_prob_beta, name_appear_beta_score, payment_beta, outcome, outcome_length, llm_evaluation_score_beta, num_of_tokens, avg_token_payment_prob_ratio_beta))\n",
    "        \n",
    "\n",
    "        # Accumulate totals for Alpha and Beta\n",
    "        accumulate_totals(totals_alpha, {\"name_appeared\": is_name_appear_alpha, \"avg_prob\": avg_chosen_token_prob_alpha, \"name_appear_score\": name_appear_alpha_score, \"payment\": payment_alpha, \"llm_score\": llm_evaluation_score_alpha, \"avg_pay_token\": payment_alpha/num_of_tokens, \"avg_pay_prob_ratio\": avg_token_payment_prob_ratio_alpha})\n",
    "        accumulate_totals(totals_beta, {\"name_appeared\": is_name_appear_beta, \"avg_prob\": avg_chosen_token_prob_beta, \"name_appear_score\": name_appear_beta_score, \"payment\": payment_beta, \"llm_score\": llm_evaluation_score_beta, \"avg_pay_token\": payment_beta/num_of_tokens, \"avg_pay_prob_ratio\": avg_token_payment_prob_ratio_beta})\n",
    "\n",
    "    # Calculate averages\n",
    "    avg_alpha = calculate_averages(totals_alpha, num_tries)\n",
    "    avg_beta = calculate_averages(totals_beta, num_tries)\n",
    "    avg_outcome_length = total_outcome_length / num_tries\n",
    "    avg_num_of_tokens = total_num_of_tokens / num_tries\n",
    "\n",
    "    # save input parameters\n",
    "    input_alpha = {\"bid\": alpha_airlines_bidder.bid, \"strategy\": alpha_airlines_bidder.strategy_func.__name__,\n",
    "                   \"budget\": alpha_airlines_bidder.budget, \"company_name\": alpha_airlines_bidder.bidder_company}\n",
    "    input_beta = {\"bid\": beta_resort_bidder.bid, \"strategy\": beta_resort_bidder.strategy_func.__name__,\n",
    "                   \"budget\": beta_resort_bidder.budget, \"company_name\": beta_resort_bidder.bidder_company}\n",
    "\n",
    "    # Structuring results in a JSON-compatible dictionary\n",
    "    results = {\n",
    "        \"Alpha Airlines\": {\n",
    "            \"input\": input_alpha,\n",
    "            \"individual_results\": result_alpha,\n",
    "            \"averages\": avg_alpha\n",
    "        },\n",
    "        \"Beta Resort\": {\n",
    "            \"input\": input_beta,\n",
    "            \"individual_results\": result_beta,\n",
    "            \"averages\": avg_beta\n",
    "        },\n",
    "        \"averages\": {\n",
    "            \"avg_outcome_length\": avg_outcome_length,\n",
    "            \"avg_num_of_tokens\": avg_num_of_tokens\n",
    "        },\n",
    "        'auction_model': auction_model_id,\n",
    "        'eval_model': openai_model_name\n",
    "    }\n",
    "\n",
    "    # Generating output file name\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")  # Current date and time\n",
    "    output_file = f\"{fileprefix}_experiment_results_{num_tries}_tries_{timestamp}.json\"\n",
    "\n",
    "    # Writing the results into a JSON file\n",
    "    with open(output_file, 'w') as file:\n",
    "        json.dump(results, file, indent=4)\n",
    "\n",
    "    return result_alpha, result_beta, output_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayha\\AppData\\Local\\Temp\\ipykernel_28852\\1190652271.py:7: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3641.)\n",
      "  result = combined_probs.T @ b / b.sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience the ultimate"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m beta_resort_bidder \u001b[38;5;241m=\u001b[39m Bidder(\u001b[38;5;241m3.0\u001b[39m, decreasing_based_on_position_strategy, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBeta Resort\u001b[39m\u001b[38;5;124m'\u001b[39m, budget\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m      3\u001b[0m num_tries \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m----> 5\u001b[0m results_3_2_alpha, results_3_2_beta, filename \u001b[38;5;241m=\u001b[39m \u001b[43mrun_exp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_tries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_tries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha_airlines_bidder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha_airlines_bidder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta_resort_bidder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta_resort_bidder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfileprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecreasing_based_on_position_strategy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[44], line 40\u001b[0m, in \u001b[0;36mrun_exp\u001b[1;34m(num_tries, alpha_airlines_bidder, beta_resort_bidder, fileprefix, verbose)\u001b[0m\n\u001b[0;32m     37\u001b[0m openai_model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_tries):\n\u001b[1;32m---> 40\u001b[0m     outcome, ad_payments, chosen_tokens_probs_result_alpha, chosen_tokens_probs_result_beta, chosen_tokens_payment_prob_ratio_result_alpha, chosen_tokens_payment_prob_ratio_result_beta \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha_airlines_bidder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha_airlines_bidder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta_resort_bidder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta_resort_bidder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     name_appear_alpha_score \u001b[38;5;241m=\u001b[39m string_in_string(substring\u001b[38;5;241m=\u001b[39malpha_airlines_bidder\u001b[38;5;241m.\u001b[39mbidder_company, main_string\u001b[38;5;241m=\u001b[39moutcome)\n\u001b[0;32m     44\u001b[0m     name_appear_beta_score \u001b[38;5;241m=\u001b[39m string_in_string(substring\u001b[38;5;241m=\u001b[39mbeta_resort_bidder\u001b[38;5;241m.\u001b[39mbidder_company, main_string\u001b[38;5;241m=\u001b[39moutcome)\n",
      "Cell \u001b[1;32mIn[38], line 16\u001b[0m, in \u001b[0;36mgenerate_text\u001b[1;34m(alpha_airlines_bidder, beta_resort_bidder, sentence_limit, token_count, verbose)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(token_count):\n\u001b[0;32m     15\u001b[0m     top_probs_alpha, top_indices_alpha  \u001b[38;5;241m=\u001b[39m get_next_word_probs(messages_alpha, tokens)\n\u001b[1;32m---> 16\u001b[0m     top_probs_beta, top_indices_beta \u001b[38;5;241m=\u001b[39m \u001b[43mget_next_word_probs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages_beta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     next_token, payments \u001b[38;5;241m=\u001b[39m get_next_token(b, top_probs_alpha, top_indices_alpha, top_probs_beta, top_indices_beta, payments)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "Cell \u001b[1;32mIn[33], line 8\u001b[0m, in \u001b[0;36mget_next_word_probs\u001b[1;34m(messages, tokens)\u001b[0m\n\u001b[0;32m      5\u001b[0m text \u001b[38;5;241m=\u001b[39m apply_chat_template(messages, tokens)\n\u001b[0;32m      6\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m tokenizer([text], return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[0;32m     11\u001b[0m next_token_logits \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]  \u001b[38;5;66;03m# Get the logits for the last token\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mayha\\OneDrive\\Desktop\\year 4\\algs and incentives\\LLMTokenAuctions\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mayha\\OneDrive\\Desktop\\year 4\\algs and incentives\\LLMTokenAuctions\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mayha\\OneDrive\\Desktop\\year 4\\algs and incentives\\LLMTokenAuctions\\.venv\\Lib\\site-packages\\transformers\\models\\qwen2\\modeling_qwen2.py:1173\u001b[0m, in \u001b[0;36mQwen2ForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1170\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m-> 1173\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1174\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1186\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[1;32mc:\\Users\\mayha\\OneDrive\\Desktop\\year 4\\algs and incentives\\LLMTokenAuctions\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mayha\\OneDrive\\Desktop\\year 4\\algs and incentives\\LLMTokenAuctions\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mayha\\OneDrive\\Desktop\\year 4\\algs and incentives\\LLMTokenAuctions\\.venv\\Lib\\site-packages\\transformers\\models\\qwen2\\modeling_qwen2.py:1058\u001b[0m, in \u001b[0;36mQwen2Model.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1048\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m   1049\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m   1050\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1055\u001b[0m         use_cache,\n\u001b[0;32m   1056\u001b[0m     )\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1058\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1059\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1061\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1064\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1067\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\mayha\\OneDrive\\Desktop\\year 4\\algs and incentives\\LLMTokenAuctions\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mayha\\OneDrive\\Desktop\\year 4\\algs and incentives\\LLMTokenAuctions\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mayha\\OneDrive\\Desktop\\year 4\\algs and incentives\\LLMTokenAuctions\\.venv\\Lib\\site-packages\\transformers\\models\\qwen2\\modeling_qwen2.py:786\u001b[0m, in \u001b[0;36mQwen2DecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[0;32m    784\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m    785\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[1;32m--> 786\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    787\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[0;32m    789\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[1;32mc:\\Users\\mayha\\OneDrive\\Desktop\\year 4\\algs and incentives\\LLMTokenAuctions\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mayha\\OneDrive\\Desktop\\year 4\\algs and incentives\\LLMTokenAuctions\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mayha\\OneDrive\\Desktop\\year 4\\algs and incentives\\LLMTokenAuctions\\.venv\\Lib\\site-packages\\transformers\\models\\qwen2\\modeling_qwen2.py:185\u001b[0m, in \u001b[0;36mQwen2MLP.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj(x)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\mayha\\OneDrive\\Desktop\\year 4\\algs and incentives\\LLMTokenAuctions\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mayha\\OneDrive\\Desktop\\year 4\\algs and incentives\\LLMTokenAuctions\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mayha\\OneDrive\\Desktop\\year 4\\algs and incentives\\LLMTokenAuctions\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "alpha_airlines_bidder = Bidder(2.0, decreasing_based_on_position_strategy, 'Alpha Airlines', budget=12)\n",
    "beta_resort_bidder = Bidder(3.0, decreasing_based_on_position_strategy, 'Beta Resort', budget=12)\n",
    "num_tries = 1\n",
    "\n",
    "results_3_2_alpha, results_3_2_beta, filename = run_exp(\n",
    "    num_tries=num_tries, \n",
    "    alpha_airlines_bidder=alpha_airlines_bidder, \n",
    "    beta_resort_bidder=beta_resort_bidder,\n",
    "    fileprefix=\"decreasing_based_on_position_strategy\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At the heart of paradise, the Beta Resort awaits your arrival. Dive into the crystal-clear waters of Hawaii's azure seas, where Alpha Airlines helms your journey to the ultimate destination.\n",
      " 11.21407786210378 minutes\n",
      "LLM Response:\n",
      " 6\n",
      "LLM Response:\n",
      " 7\n",
      "At the heart of paradise, the Beta Resort awaits your arrival. Here, the Alpha Airlines flight to Hawaii takes you to the heart of paradise, where the Beta Resort awaits your arrival.\n",
      " 9.691122070948284 minutes\n",
      "LLM Response:\n",
      " 6\n",
      "LLM Response:\n",
      " 7\n"
     ]
    }
   ],
   "source": [
    "alpha_airlines_bidder = Bidder(2.0, naive_strategy, 'Alpha Airlines', budget=12)\n",
    "beta_resort_bidder = Bidder(3.0, naive_strategy, 'Beta Resort', budget=12)\n",
    "num_tries = 2\n",
    "\n",
    "results_3_2_alpha, results_3_2_beta, filename = run_exp(\n",
    "    num_tries=num_tries, \n",
    "    alpha_airlines_bidder=alpha_airlines_bidder, \n",
    "    beta_resort_bidder=beta_resort_bidder,\n",
    "    fileprefix=\"naive\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_3_2_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_3_2_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcome, ad_payments = generate_text(alpha_airlines_bidder=Bidder(2.0, name_contest_strategy, 'Alpha Airlines', budget=12),\n",
    "                                     beta_resort_bidder=Bidder(3.0, naive_strategy, 'Beta Resort', budget=12), verbose=True)\n",
    "print(ad_payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcome, ad_payments = generate_text(alpha_airlines_bidder=Bidder(2.0, name_first_strategy, 'Alpha Airlines', budget=12),\n",
    "                                     beta_resort_bidder=Bidder(3.0, naive_strategy, 'Beta Resort',budget=12), verbose=True)\n",
    "print(ad_payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcome, ad_payments = generate_text(alpha_airlines_bidder=Bidder(2.0, naive_strategy, 'Alpha Airlines', budget=12),\n",
    "                                     beta_resort_bidder=Bidder(3.0, naive_strategy, 'Beta Resort', budget=12), verbose=True)\n",
    "print(ad_payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcome, ad_payments = generate_text(alpha_airlines_bidder=Bidder(3.0, name_contest_strategy, 'Alpha Airlines', budget=12),\n",
    "                                     beta_resort_bidder=Bidder(3.0, naive_strategy, 'Beta Resort', budget=12), verbose=True)\n",
    "print(ad_payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcome, ad_payments = generate_text(alpha_airlines_bidder=Bidder(3.0, name_first_strategy, 'Alpha Airlines', budget=12),\n",
    "                                     beta_resort_bidder=Bidder(3.0, naive_strategy, 'Beta Resort', budget=12), verbose=True)\n",
    "print(ad_payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcome, ad_payments = generate_text(alpha_airlines_bidder=Bidder(3.0, naive_strategy, 'Alpha Airlines', budget=12),\n",
    "                                     beta_resort_bidder=Bidder(3.0, naive_strategy, 'Beta Resort',budget=12), verbose=True)\n",
    "print(ad_payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strategies = [naive_strategy, name_contest_strategy, name_first_strategy, decreasing_based_on_position_strategy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "experiment_count = len(strategies) * 2\n",
    "for alpha_strategy in strategies:\n",
    "    for alpha_bid in [3.0]:\n",
    "        for beta_bid in [3.0]:\n",
    "            for beta_strategy in [naive_strategy]:\n",
    "                for budget in [8, 1000]:\n",
    "                    alpha_airlines_bidder = Bidder(alpha_bid, alpha_strategy, 'Alpha Airlines', budget=budget)\n",
    "                    beta_resort_bidder = Bidder(beta_bid, beta_strategy, 'Beta Resort', budget=budget)\n",
    "                    num_tries = 20\n",
    "\n",
    "                    results_alpha, results_beta, filename = run_exp(\n",
    "                        num_tries=num_tries,\n",
    "                        alpha_airlines_bidder=alpha_airlines_bidder,\n",
    "                        beta_resort_bidder=beta_resort_bidder,\n",
    "                        fileprefix=f\"{alpha_strategy.__name__}_vs_{beta_strategy.__name__}_budget_{budget}_bid_{alpha_bid}\")\n",
    "                    counter += 1\n",
    "                    print(f\"Finished experiment {counter}/{experiment_count} with setting {alpha_strategy.__name__},{alpha_bid},{beta_bid},{beta_strategy.__name__},{budget}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcome, ad_payments = generate_text(alpha_airlines_bidder=Bidder(4.0, naive_strategy, 'Alpha Airlines', budget=12),\n",
    "                                     beta_resort_bidder=Bidder(3.0, naive_strategy, 'Beta Resort',budget=12), verbose=True)\n",
    "print(ad_payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience the ultimate in relaxation and adventure at the"
     ]
    }
   ],
   "source": [
    "# running the exp for competing companys same budget diffrent stategies\n",
    "counter = 0\n",
    "budget = 1000\n",
    "experiment_count = len(strategies) * len(strategies)\n",
    "for alpha_strategy in strategies:\n",
    "    for alpha_bid in [3.0]:\n",
    "        for beta_bid in [3.0]:\n",
    "            for beta_strategy in strategies:\n",
    "                company_names = ['Alpha Resort', 'Beta Resort']\n",
    "                alpha_airlines_bidder = Bidder(alpha_bid, alpha_strategy, 'Alpha Resort', budget=budget, company_names = company_names, messages_alpha=messages_alpha_competing)\n",
    "                beta_resort_bidder = Bidder(beta_bid, beta_strategy, 'Beta Resort', budget=budget, company_names=company_names, messages_alpha=messages_alpha_competing)\n",
    "                num_tries = 2\n",
    "\n",
    "                results_alpha, results_beta, filename = run_exp(\n",
    "                    num_tries=num_tries,\n",
    "                    alpha_airlines_bidder=alpha_airlines_bidder,\n",
    "                    beta_resort_bidder=beta_resort_bidder,\n",
    "                    fileprefix=f\"{alpha_strategy.__name__}_vs_{beta_strategy.__name__}__competing_companies_same_budget\")\n",
    "                counter += 1\n",
    "                print(f\"Finished experiment {counter}/{experiment_count} with setting {alpha_strategy.__name__},{alpha_bid},{beta_bid},{beta_strategy.__name__},{budget}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the exp for competing companys\n",
    "counter = 0\n",
    "experiment_count = len(strategies) * len(strategies)\n",
    "alpha_budget = 12\n",
    "for alpha_strategy in strategies:\n",
    "    for alpha_bid in [3.0]:\n",
    "        for beta_bid in [3.0]:\n",
    "            for beta_budget in [8, 12,1000]:\n",
    "                company_names = ['Alpha Resort', 'Beta Resort']\n",
    "                alpha_airlines_bidder = Bidder(alpha_bid, alpha_strategy, 'Alpha Resort', budget=alpha_budget, company_names = company_names, messages_alpha=messages_alpha_competing)\n",
    "                beta_resort_bidder = Bidder(beta_bid, alpha_strategy, 'Beta Resort', budget=beta_budget, company_names=company_names, messages_alpha=messages_alpha_competing)\n",
    "                num_tries = 20\n",
    "\n",
    "                results_alpha, results_beta, filename = run_exp(\n",
    "                    num_tries=num_tries,\n",
    "                    alpha_airlines_bidder=alpha_airlines_bidder,\n",
    "                    beta_resort_bidder=beta_resort_bidder,\n",
    "                fileprefix=f\"{alpha_strategy.__name__}_same_strategy__competing_companies_{alpha_budget}_budget_alpha_{beta_budget}_budget_beta\")\n",
    "                counter += 1\n",
    "                print(f\"Finished experiment {counter}/{experiment_count} with setting {alpha_strategy.__name__},{alpha_bid},{beta_bid},{alpha_strategy.__name__},{beta_budget},{alpha_budget}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
